{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Week 3: Multi-Agent Orchestration\n",
        "\n",
        "## Supervisor Pattern, Subgraphs & Shared State\n",
        "\n",
        "Welcome to Week 3! Last week you built a single ReAct agent. Today, you'll build a **team of agents** that work together.\n",
        "\n",
        "> **üìö Official Documentation:** This notebook follows the [LangGraph Official Documentation](https://docs.langchain.com/oss/python/langgraph/overview). All APIs and patterns used here are based on the current LangGraph specification.\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Recap & Today's Plan\n",
        "\n",
        "**Last week:** Typed State, Conditional Edges, Checkpointing, Meeting Prep Agent\n",
        "\n",
        "**Today:** Your Week 1 router + your Week 2 ReAct agent combine into a real multi-agent system.\n",
        "\n",
        "*\"Last week you built the employee. Today you build the team.\"*\n",
        "\n",
        "**Today's agenda:** \n",
        "1. Supervisor Pattern ‚Üí \n",
        "2. Shared vs Scoped State ‚Üí \n",
        "3. Subgraphs ‚Üí \n",
        "4. Live Build\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ What You'll Learn Today\n",
        "\n",
        "1. **Why Multi-Agent?** ‚Äî When and why to split work across agents\n",
        "2. **Supervisor Pattern** ‚Äî The coordinator that never does the work\n",
        "3. **Shared vs Scoped State** ‚Äî What each agent sees vs what stays private\n",
        "4. **Subgraphs** ‚Äî Agents as nodes in a parent graph\n",
        "5. **Live Build** ‚Äî Company Research Assistant with 3 agents\n",
        "\n",
        "### üéØ By the End of This Notebook\n",
        "\n",
        "- ‚úÖ Understand when to use multi-agent systems\n",
        "- ‚úÖ Implement the Supervisor Pattern in LangGraph\n",
        "- ‚úÖ Design shared and scoped state schemas\n",
        "- ‚úÖ Build subgraphs and compose them into parent graphs\n",
        "- ‚úÖ Create a working Company Research Assistant\n",
        "- ‚úÖ Debug common multi-agent issues\n",
        "\n",
        "---\n",
        "\n",
        "### üìñ How to Use This Notebook\n",
        "\n",
        "1. **Run cells in order** - Each cell builds on the previous one\n",
        "2. **Read the markdown cells** - They contain important explanations\n",
        "3. **Experiment** - Try modifying the code to see what happens\n",
        "4. **Complete the homework** - Extend the system with a third agent\n",
        "\n",
        "**Ready? Let's start!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup & Installation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîë API Key Setup (IMPORTANT!)\n",
        "\n",
        "**To get REAL data instead of mock data, you need to set up API keys:**\n",
        "\n",
        "1. **Create a `.env` file** in the `week-3` directory\n",
        "2. **Add your API keys:**\n",
        "   ```\n",
        "   OPENAI_API_KEY=your_openai_api_key_here\n",
        "   TAVILY_API_KEY=your_tavily_api_key_here\n",
        "   ```\n",
        "\n",
        "3. **Get your API keys:**\n",
        "   - **OpenAI**: https://platform.openai.com/api-keys\n",
        "   - **Tavily**: https://tavily.com (free tier available)\n",
        "\n",
        "**Without API keys, the system will use mock data for demonstration purposes.**\n",
        "\n",
        "You can copy `.env.example` to `.env` and fill in your keys:\n",
        "```bash\n",
        "cp .env.example .env\n",
        "# Then edit .env with your actual keys\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once)\n",
        "%pip install langgraph langchain-core langchain-openai langchain ipython python-dotenv tavily-python\n",
        "\n",
        "# Verify installation\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(\"‚úÖ Dependencies installed successfully!\")\n",
        "print(\"üí° Make sure you have a .env file with OPENAI_API_KEY and TAVILY_API_KEY!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import operator\n",
        "from typing import Annotated, Literal\n",
        "from typing_extensions import TypedDict\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# Load environment variables\n",
        "# Try loading from current directory first, then parent directory\n",
        "env_path = Path(\".env\")\n",
        "if not env_path.exists():\n",
        "    env_path = Path(\"../.env\")\n",
        "if not env_path.exists():\n",
        "    env_path = Path(\"../../.env\")\n",
        "\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Tavily Search import\n",
        "try:\n",
        "    from tavily import TavilyClient\n",
        "    TAVILY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TAVILY_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è  Tavily not installed. Install with: pip install tavily-python\")\n",
        "\n",
        "# Verify API keys\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üîë API Key Status:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if api_key:\n",
        "    print(\"‚úÖ OpenAI API key loaded\")\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "else:\n",
        "    print(\"‚ùå OPENAI_API_KEY not found\")\n",
        "    print(\"   üìù To fix: Create a .env file with:\")\n",
        "    print(\"      OPENAI_API_KEY=your_key_here\")\n",
        "    print(\"   üîó Get your key: https://platform.openai.com/api-keys\")\n",
        "    llm = None\n",
        "\n",
        "if tavily_key and TAVILY_AVAILABLE:\n",
        "    print(\"‚úÖ Tavily API key loaded\")\n",
        "    tavily_client = TavilyClient(api_key=tavily_key)\n",
        "else:\n",
        "    print(\"‚ùå TAVILY_API_KEY not found or Tavily not installed\")\n",
        "    if not TAVILY_AVAILABLE:\n",
        "        print(\"   üìù Install Tavily: pip install tavily-python\")\n",
        "    print(\"   üìù To fix: Add to .env file:\")\n",
        "    print(\"      TAVILY_API_KEY=your_key_here\")\n",
        "    print(\"   üîó Get your key: https://tavily.com (free tier available)\")\n",
        "    tavily_client = None\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not api_key or not tavily_key:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: Missing API keys will result in MOCK DATA\")\n",
        "    print(\"   The system will work but return placeholder responses.\")\n",
        "    print(\"   To get real data, set up your API keys in a .env file.\\n\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ All API keys configured! Ready for real data.\\n\")\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üìö Concept 1: Why Multi-Agent?\n",
        "\n",
        "## Single Agents Break When:\n",
        "\n",
        "- **Tasks have too many steps** ‚Äî context overload\n",
        "- **You need different expertise** for different parts\n",
        "- **One failure takes everything down** ‚Äî no isolation\n",
        "- **You need to run things simultaneously** ‚Äî parallel execution\n",
        "\n",
        "## Multi-Agent Systems Give You:\n",
        "\n",
        "| Benefit | Description |\n",
        "|---------|-------------|\n",
        "| **Specialization** | Each agent does one thing well |\n",
        "| **Isolation** | Failures are contained |\n",
        "| **Scalability** | Agents can run in parallel |\n",
        "| **Maintainability** | Swap one agent without breaking the rest |\n",
        "\n",
        "*\"One agent, ten tasks = one person doing every job in the company.\"*\n",
        "\n",
        "---\n",
        "\n",
        "# üìö Concept 2: The Supervisor Pattern\n",
        "\n",
        "## The Supervisor Never Does the Work. It Only Decides Who Does.\n",
        "\n",
        "```\n",
        "User ‚Üí Supervisor ‚Üí Researcher ‚Üí Supervisor ‚Üí Writer ‚Üí Supervisor (FINISH) ‚Üí User\n",
        "```\n",
        "\n",
        "### How It Works:\n",
        "\n",
        "1. Supervisor reads the task and current state\n",
        "2. Outputs a routing decision: `researcher` / `writer` / `FINISH`\n",
        "3. Specialist agent runs and writes results to shared state\n",
        "4. Supervisor reads again and decides what's next\n",
        "5. Repeat until FINISH\n",
        "\n",
        "**The routing function** ‚Äî same conditional edges from Week 2, now routing between agents instead of tools.\n",
        "\n",
        "### Bad Supervisor Prompt:\n",
        "```\n",
        "You manage a team. Decide who goes next. Members: researcher, writer\n",
        "```\n",
        "\n",
        "### Good Supervisor Prompt:\n",
        "```\n",
        "Route to researcher if research is not done.\n",
        "Route to writer if research is done but no draft exists.\n",
        "Respond FINISH if both research and draft are complete.\n",
        "Reply with exactly one word: researcher, writer, or FINISH.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üìö Concept 3: Shared vs Scoped State\n",
        "\n",
        "## Shared State ‚Äî Visible to Everyone\n",
        "\n",
        "The supervisor reads this to make decisions. All agents can read/write shared state.\n",
        "\n",
        "## Scoped State ‚Äî Private to a Subgraph\n",
        "\n",
        "Internal reasoning, intermediate results, tool call noise. Never reaches the supervisor.\n",
        "\n",
        "### Example:\n",
        "\n",
        "```python\n",
        "# Shared ‚Äî supervisor sees this\n",
        "class SupervisorState(TypedDict):\n",
        "    task: str\n",
        "    research_summary: str   # clean output from researcher\n",
        "    draft: str              # clean output from writer\n",
        "    next: str               # routing decision\n",
        "\n",
        "# Scoped ‚Äî researcher only\n",
        "class ResearchState(TypedDict):\n",
        "    query: str\n",
        "    raw_search_results: List[str]   # internal noise\n",
        "    research_summary: str            # only this goes back up\n",
        "```\n",
        "\n",
        "**Rule of thumb:** Shared state = what the supervisor needs + what the user sees. Everything else = scoped.\n",
        "\n",
        "**What breaks without it:** Every agent's internal tool calls, search results, and scratchpad pile into shared messages. Supervisor starts making routing decisions based on noise. Quality collapses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üìö Concept 4: Subgraphs\n",
        "\n",
        "## A Subgraph is a Compiled LangGraph App Used as a Single Node\n",
        "\n",
        "From the parent's perspective: **black box**. Input in, output out.\n",
        "Internally: its own state, nodes, edges, loops, tools.\n",
        "\n",
        "### How It Works:\n",
        "\n",
        "```python\n",
        "# Build the subgraph\n",
        "research_graph = StateGraph(ResearchState)\n",
        "research_graph.add_node(\"search\", search_node)\n",
        "research_graph.add_node(\"summarize\", summarize_node)\n",
        "research_graph.add_edge(START, \"search\")\n",
        "research_graph.add_edge(\"search\", \"summarize\")\n",
        "research_graph.add_edge(\"summarize\", END)\n",
        "research_agent = research_graph.compile()\n",
        "\n",
        "# Drop it into the parent as a single node\n",
        "parent_graph.add_node(\"researcher\", research_agent)\n",
        "```\n",
        "\n",
        "**State handoff:** Fields that exist in both parent state and subgraph state are passed automatically. Only matching fields flow in and out.\n",
        "\n",
        "**Your Week 2 Meeting Prep Agent is already a subgraph. It just doesn't know it yet.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üèóÔ∏è What We're Building\n",
        "\n",
        "## Company Research Assistant\n",
        "\n",
        "**Three agents. One goal:** Type in a company name, get back a structured brief.\n",
        "\n",
        "| Agent | Role |\n",
        "|-------|------|\n",
        "| **Supervisor** | Reads the task, decides who acts, synthesizes the final output |\n",
        "| **Research Agent** | Runs web searches, returns a clean 3-paragraph summary |\n",
        "| **Writer Agent** | Takes the summary, writes a structured brief: Overview / Recent Developments / Outreach Signals |\n",
        "\n",
        "### Project Structure:\n",
        "\n",
        "```\n",
        "week-3/\n",
        "‚îú‚îÄ‚îÄ state.py          # SupervisorState and ResearchState\n",
        "‚îú‚îÄ‚îÄ agents/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ supervisor.py # Routing logic and FINISH condition\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ researcher.py # Research subgraph with search + summarize\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ writer.py     # Writer node that drafts the brief\n",
        "‚îú‚îÄ‚îÄ graph.py          # Wire all nodes, add conditional edges\n",
        "‚îî‚îÄ‚îÄ main.py           # Invoke and print output\n",
        "```\n",
        "\n",
        "**Let's build it step by step!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üî® Live Build: Step 1 - Define State Schemas\n",
        "\n",
        "## Shared State (SupervisorState)\n",
        "\n",
        "This is what the supervisor sees and uses to make routing decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shared state - visible to supervisor and all agents\n",
        "class SupervisorState(TypedDict):\n",
        "    \"\"\"State shared across all agents. Supervisor reads this to make decisions.\"\"\"\n",
        "    task: str                    # Company name to research\n",
        "    research_summary: str        # Clean output from researcher (3 paragraphs)\n",
        "    draft: str                  # Clean output from writer (structured brief)\n",
        "    next: str                   # Routing decision: \"researcher\", \"writer\", or \"FINISH\"\n",
        "    messages: Annotated[list, operator.add]  # Conversation history\n",
        "\n",
        "print(\"‚úÖ SupervisorState defined (shared state)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scoped State (ResearchState)\n",
        "\n",
        "This is private to the research subgraph. Only `research_summary` flows back to shared state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scoped state - private to research subgraph\n",
        "class ResearchState(TypedDict):\n",
        "    \"\"\"State internal to the research subgraph. Only research_summary flows back up.\"\"\"\n",
        "    task: str                    # Matches SupervisorState.task (auto-passed)\n",
        "    raw_search_results: list      # Internal noise - never seen by supervisor\n",
        "    research_summary: str         # Clean output - flows back to SupervisorState\n",
        "    messages: Annotated[list, operator.add]  # Internal conversation\n",
        "\n",
        "print(\"‚úÖ ResearchState defined (scoped state)\")\n",
        "print(\"üí° Note: 'task' and 'research_summary' match SupervisorState - they auto-flow!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üî® Live Build: Step 2 - Research Agent (Subgraph)\n",
        "\n",
        "The research agent is a **subgraph** with two nodes:\n",
        "1. **search_node** - Runs web searches using Tavily\n",
        "2. **summarize_node** - Condenses results into 3 clean paragraphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool: Web search using Tavily\n",
        "@tool\n",
        "def tavily_search(query: str) -> str:\n",
        "    \"\"\"Search the web for information about a company.\"\"\"\n",
        "    if not tavily_client:\n",
        "        return f\"[Mock] Search results for: {query}\"\n",
        "    \n",
        "    try:\n",
        "        response = tavily_client.search(\n",
        "            query=query,\n",
        "            search_depth=\"advanced\",\n",
        "            max_results=5\n",
        "        )\n",
        "        results = []\n",
        "        for result in response.get(\"results\", []):\n",
        "            results.append(f\"Title: {result.get('title', 'N/A')}\\nContent: {result.get('content', 'N/A')}\")\n",
        "        return \"\\n\\n---\\n\\n\".join(results)\n",
        "    except Exception as e:\n",
        "        return f\"Error searching: {str(e)}\"\n",
        "\n",
        "print(\"‚úÖ Tavily search tool defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Node 1: Search node - runs web searches\n",
        "def search_node(state: ResearchState) -> dict:\n",
        "    \"\"\"Search the web for information about the company.\"\"\"\n",
        "    task = state.get(\"task\", \"\")\n",
        "    if not task:\n",
        "        return {\"research_summary\": \"No task provided\"}\n",
        "    \n",
        "    # Search for the company\n",
        "    search_query = f\"{task} company overview recent news\"\n",
        "    search_results = tavily_search.invoke({\"query\": search_query})\n",
        "    \n",
        "    return {\n",
        "        \"raw_search_results\": [search_results],  # Internal - stays in scoped state\n",
        "        \"messages\": [ToolMessage(content=search_results, tool_call_id=\"search_1\")]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Search node defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Node 2: Summarize node - condenses search results into clean summary\n",
        "def summarize_node(state: ResearchState) -> dict:\n",
        "    \"\"\"Summarize search results into 3 clean paragraphs.\"\"\"\n",
        "    if not llm:\n",
        "        return {\"research_summary\": \"[Mock] Research summary: Company overview, recent developments, and market position.\"}\n",
        "    \n",
        "    raw_results = state.get(\"raw_search_results\", [])\n",
        "    task = state.get(\"task\", \"\")\n",
        "    \n",
        "    if not raw_results:\n",
        "        return {\"research_summary\": f\"No search results found for {task}\"}\n",
        "    \n",
        "    # Combine all search results\n",
        "    combined_results = \"\\n\\n\".join(raw_results)\n",
        "    \n",
        "    # Use LLM to create a clean 3-paragraph summary\n",
        "    prompt = f\"\"\"Based on the following search results, write a clean 3-paragraph summary about {task}.\n",
        "\n",
        "Search Results:\n",
        "{combined_results}\n",
        "\n",
        "Write exactly 3 paragraphs:\n",
        "1. Company Overview (what they do, industry, size)\n",
        "2. Recent Developments (news, product launches, partnerships)\n",
        "3. Market Position (competitors, growth, outlook)\n",
        "\n",
        "Keep it concise and factual. Only use information from the search results.\"\"\"\n",
        "\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    summary = response.content\n",
        "    \n",
        "    return {\n",
        "        \"research_summary\": summary,  # This flows back to SupervisorState!\n",
        "        \"messages\": [AIMessage(content=summary)]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Summarize node defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the research subgraph\n",
        "research_graph = StateGraph(ResearchState)\n",
        "\n",
        "# Add nodes\n",
        "research_graph.add_node(\"search\", search_node)\n",
        "research_graph.add_node(\"summarize\", summarize_node)\n",
        "\n",
        "# Wire edges: START -> search -> summarize -> END\n",
        "research_graph.add_edge(START, \"search\")\n",
        "research_graph.add_edge(\"search\", \"summarize\")\n",
        "research_graph.add_edge(\"summarize\", END)\n",
        "\n",
        "# Compile the subgraph\n",
        "research_agent = research_graph.compile()\n",
        "\n",
        "print(\"‚úÖ Research subgraph compiled!\")\n",
        "print(\"üí° This subgraph will be used as a single node in the parent graph\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üî® Live Build: Step 3 - Writer Agent\n",
        "\n",
        "The writer agent takes the research summary and creates a structured brief.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Writer node - creates structured brief from research summary\n",
        "def writer_node(state: SupervisorState) -> dict:\n",
        "    \"\"\"Write a structured brief from the research summary.\"\"\"\n",
        "    if not llm:\n",
        "        return {\"draft\": \"[Mock] Structured brief:\\n\\n## Overview\\nCompany details...\\n\\n## Recent Developments\\nNews...\\n\\n## Outreach Signals\\nOpportunities...\"}\n",
        "    \n",
        "    research_summary = state.get(\"research_summary\", \"\")\n",
        "    task = state.get(\"task\", \"\")\n",
        "    \n",
        "    if not research_summary:\n",
        "        return {\"draft\": f\"No research summary available for {task}\"}\n",
        "    \n",
        "    prompt = f\"\"\"Based on the following research summary, write a structured company brief for {task}.\n",
        "\n",
        "Research Summary:\n",
        "{research_summary}\n",
        "\n",
        "Format the brief with these sections:\n",
        "1. **Overview** - Company description, industry, key facts\n",
        "2. **Recent Developments** - Latest news, product launches, partnerships\n",
        "3. **Outreach Signals** - Opportunities for engagement, pain points, growth areas\n",
        "\n",
        "Keep it professional and actionable.\"\"\"\n",
        "\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    draft = response.content\n",
        "    \n",
        "    return {\n",
        "        \"draft\": draft,\n",
        "        \"messages\": [AIMessage(content=f\"Brief written for {task}\")]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Writer node defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üî® Live Build: Step 4 - Supervisor Agent\n",
        "\n",
        "The supervisor reads the state and decides who acts next. It never does the work itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Supervisor node - decides routing\n",
        "def supervisor_node(state: SupervisorState) -> dict:\n",
        "    \"\"\"Supervisor reads state and decides who acts next.\n",
        "    \n",
        "    IMPORTANT: Uses boolean state checks to prevent infinite loops.\n",
        "    Never rely solely on LLM inference for routing decisions.\n",
        "    \"\"\"\n",
        "    # Use boolean checks, not LLM inference (prevents infinite loops)\n",
        "    research_summary = state.get(\"research_summary\", \"\").strip()\n",
        "    draft = state.get(\"draft\", \"\").strip()\n",
        "    \n",
        "    # Debug: Print state to help diagnose issues\n",
        "    # print(f\"DEBUG Supervisor - research_summary: {bool(research_summary)}, draft: {bool(draft)}\")\n",
        "    \n",
        "    # Make routing decision based on state (deterministic, prevents loops)\n",
        "    # IMPORTANT: Check draft FIRST if both exist, to prevent re-running researcher\n",
        "    if draft and len(draft) > 10:  # Draft exists and is substantial\n",
        "        decision = \"FINISH\"\n",
        "    elif research_summary and len(research_summary) > 10:  # Research done, need draft\n",
        "        decision = \"writer\"\n",
        "    else:  # Need research\n",
        "        decision = \"researcher\"\n",
        "    \n",
        "    # Optional: Use LLM for logging/reasoning (but decision is already made above)\n",
        "    if llm:\n",
        "        prompt = f\"\"\"You are a supervisor managing a research team.\n",
        "\n",
        "Current state:\n",
        "- Task: {state.get('task', 'N/A')}\n",
        "- Research Summary: {'‚úÖ Complete' if research_summary else '‚ùå Missing'}\n",
        "- Draft: {'‚úÖ Complete' if draft else '‚ùå Missing'}\n",
        "\n",
        "The routing decision is: {decision}\n",
        "\n",
        "Confirm this decision is correct.\"\"\"\n",
        "\n",
        "        messages = [HumanMessage(content=prompt)]\n",
        "        try:\n",
        "            response = llm.invoke(messages)\n",
        "            reasoning = response.content\n",
        "        except:\n",
        "            reasoning = \"Decision made based on state checks\"\n",
        "    else:\n",
        "        reasoning = \"Decision made based on state checks (no LLM)\"\n",
        "    \n",
        "    # Always return lowercase decision (required by routing function)\n",
        "    decision = decision.lower() if decision != \"FINISH\" else \"FINISH\"\n",
        "    \n",
        "    return {\n",
        "        \"next\": decision,\n",
        "        \"messages\": [AIMessage(content=f\"Supervisor decision: {decision} ({reasoning[:50]}...)\")]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Supervisor node defined\")\n",
        "print(\"üí° Uses deterministic boolean checks to prevent infinite loops\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Routing function - conditional edge logic\n",
        "def route_next(state: SupervisorState) -> Literal[\"researcher\", \"writer\", \"FINISH\"]:\n",
        "    \"\"\"Route to the next agent based on supervisor's decision.\n",
        "    \n",
        "    Handles case-insensitive matching to prevent routing errors.\n",
        "    \"\"\"\n",
        "    next_agent = state.get(\"next\", \"researcher\")\n",
        "    \n",
        "    # Normalize to lowercase for comparison (handle both cases)\n",
        "    next_agent_lower = str(next_agent).lower().strip()\n",
        "    \n",
        "    if next_agent_lower == \"finish\":\n",
        "        return \"FINISH\"\n",
        "    elif next_agent_lower == \"writer\":\n",
        "        return \"writer\"\n",
        "    elif next_agent_lower == \"researcher\":\n",
        "        return \"researcher\"\n",
        "    else:\n",
        "        # Fallback: default to researcher if decision is unclear\n",
        "        print(f\"‚ö†Ô∏è  Warning: Unknown routing decision '{next_agent}', defaulting to researcher\")\n",
        "        return \"researcher\"\n",
        "\n",
        "print(\"‚úÖ Routing function defined\")\n",
        "print(\"üí° Handles case-insensitive routing decisions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üî® Live Build: Step 5 - Wire the Parent Graph\n",
        "\n",
        "Now we combine everything: supervisor, research subgraph, and writer into one graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the parent graph\n",
        "parent_graph = StateGraph(SupervisorState)\n",
        "\n",
        "# Add nodes\n",
        "parent_graph.add_node(\"supervisor\", supervisor_node)\n",
        "parent_graph.add_node(\"researcher\", research_agent)  # Subgraph as a node!\n",
        "parent_graph.add_node(\"writer\", writer_node)\n",
        "\n",
        "# Wire edges\n",
        "parent_graph.add_edge(START, \"supervisor\")\n",
        "parent_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    route_next,\n",
        "    {\n",
        "        \"researcher\": \"researcher\",\n",
        "        \"writer\": \"writer\",\n",
        "        \"FINISH\": END\n",
        "    }\n",
        ")\n",
        "parent_graph.add_edge(\"researcher\", \"supervisor\")  # Back to supervisor after research\n",
        "parent_graph.add_edge(\"writer\", \"supervisor\")      # Back to supervisor after writing\n",
        "\n",
        "# Compile the graph\n",
        "app = parent_graph.compile()\n",
        "\n",
        "print(\"‚úÖ Parent graph compiled!\")\n",
        "print(\"üí° The research subgraph is now a single node in the parent graph\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üé® Visualize the Graph\n",
        "\n",
        "Let's see the structure of our multi-agent system!\n",
        "image.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the graph structure\n",
        "try:\n",
        "    from IPython.display import Image\n",
        "    \n",
        "    # Generate graph visualization\n",
        "    graph_image = app.get_graph(xray=True).draw_mermaid_png()\n",
        "    display(Image(graph_image))\n",
        "    print(\"‚úÖ Graph visualization generated!\")\n",
        "    print(\"üí° The 'researcher' node shows as a subgraph with its internal structure\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not generate visualization: {e}\")\n",
        "    print(\"üí° Install graphviz: brew install graphviz (macOS) or apt-get install graphviz (Linux)\")\n",
        "    # Fallback: print graph structure\n",
        "    print(\"\\nGraph structure:\")\n",
        "    print(\"START -> supervisor -> [researcher | writer | FINISH]\")\n",
        "    print(\"  researcher -> supervisor (loop)\")\n",
        "    print(\"  writer -> supervisor (loop)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üöÄ Test the System\n",
        "\n",
        "Let's run the Company Research Assistant!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the system\n",
        "def run_research_assistant(company_name: str, max_iterations: int = 10):\n",
        "    \"\"\"Run the research assistant for a company.\n",
        "    \n",
        "    Args:\n",
        "        company_name: Name of the company to research\n",
        "        max_iterations: Maximum number of iterations to prevent infinite loops\n",
        "    \"\"\"\n",
        "    initial_state = {\n",
        "        \"task\": company_name,\n",
        "        \"research_summary\": \"\",\n",
        "        \"draft\": \"\",\n",
        "        \"next\": \"\",\n",
        "        \"messages\": [HumanMessage(content=f\"Research {company_name}\")]\n",
        "    }\n",
        "    \n",
        "    print(f\"üîç Researching: {company_name}\\n\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Stream execution to see each step and accumulate state\n",
        "    accumulated_state = initial_state.copy()\n",
        "    iteration_count = 0\n",
        "    \n",
        "    for step in app.stream(initial_state):\n",
        "        iteration_count += 1\n",
        "        \n",
        "        # Safety check: prevent infinite loops\n",
        "        if iteration_count > max_iterations:\n",
        "            print(f\"\\n‚ö†Ô∏è  WARNING: Stopped after {max_iterations} iterations to prevent infinite loop\")\n",
        "            print(\"   This usually means the supervisor is not detecting completion correctly.\")\n",
        "            print(f\"   Current state - research_summary: {bool(accumulated_state.get('research_summary'))}, draft: {bool(accumulated_state.get('draft'))}\")\n",
        "            break\n",
        "        \n",
        "        for node, output in step.items():\n",
        "            print(f\"\\nüìç Node: {node} (iteration {iteration_count})\")\n",
        "            if node == \"supervisor\":\n",
        "                next_decision = output.get(\"next\", \"\")\n",
        "                print(f\"   Decision: {next_decision}\")\n",
        "                # Debug: show what supervisor sees\n",
        "                current_research = bool(accumulated_state.get(\"research_summary\", \"\").strip())\n",
        "                current_draft = bool(accumulated_state.get(\"draft\", \"\").strip())\n",
        "                print(f\"   State check - research: {current_research}, draft: {current_draft}\")\n",
        "            elif node == \"researcher\":\n",
        "                summary = output.get(\"research_summary\", \"\")\n",
        "                if summary:\n",
        "                    print(f\"   Research Summary: {summary[:200]}...\")\n",
        "            elif node == \"writer\":\n",
        "                draft = output.get(\"draft\", \"\")\n",
        "                if draft:\n",
        "                    print(f\"   Draft: {draft[:200]}...\")\n",
        "            \n",
        "            # Accumulate state updates (merge output into accumulated_state)\n",
        "            for key, value in output.items():\n",
        "                if key == \"messages\" and isinstance(value, list):\n",
        "                    # Append messages\n",
        "                    if \"messages\" not in accumulated_state:\n",
        "                        accumulated_state[\"messages\"] = []\n",
        "                    accumulated_state[\"messages\"].extend(value)\n",
        "                else:\n",
        "                    # Overwrite other fields (including empty strings - they're valid updates)\n",
        "                    # This ensures draft, research_summary, etc. persist\n",
        "                    accumulated_state[key] = value\n",
        "            \n",
        "            # Check if we've reached FINISH\n",
        "            if output.get(\"next\") == \"FINISH\":\n",
        "                print(\"\\n‚úÖ Supervisor decided to FINISH\")\n",
        "                break\n",
        "    \n",
        "    # Use accumulated state as final state\n",
        "    final_state = accumulated_state\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"\\n‚úÖ Final Output:\\n\")\n",
        "    \n",
        "    if final_state:\n",
        "        draft = final_state.get(\"draft\", \"\")\n",
        "        if draft:\n",
        "            print(draft)\n",
        "        else:\n",
        "            print(\"No draft generated\")\n",
        "            print(f\"Debug - Final state keys: {list(final_state.keys())}\")\n",
        "            print(f\"Debug - Draft value: {repr(final_state.get('draft', 'NOT FOUND'))}\")\n",
        "            print(f\"Debug - Research summary: {repr(final_state.get('research_summary', 'NOT FOUND'))}\")\n",
        "    \n",
        "    return final_state\n",
        "\n",
        "# Test with a company\n",
        "print(\"Ready to test! Run: run_research_assistant('OpenAI')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Research OpenAI\n",
        "result = run_research_assistant(\"OpenAI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üêõ What Breaks & How To Fix It\n",
        "\n",
        "## Common Issues and Solutions\n",
        "\n",
        "| Issue | Cause | Fix |\n",
        "|-------|-------|-----|\n",
        "| **Infinite loops** | Vague supervisor prompt, never reaches FINISH | Use boolean state checks, not LLM inference |\n",
        "| **State schema mismatch** | Parent calls it `task`, subgraph expects `query` | Print state keys at every node during development |\n",
        "| **Shared state noise** | All agents appending raw tool results to messages | Only write clean outputs to shared state, keep internals scoped |\n",
        "| **Subgraph output not reaching parent** | Field names don't match between schemas | Field names and types must be identical in both state schemas |\n",
        "\n",
        "**Always debug with `app.stream()` not `app.invoke()`**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "? w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug helper: Print state at each step\n",
        "def debug_stream(company_name: str):\n",
        "    \"\"\"Stream execution with detailed state inspection.\"\"\"\n",
        "    initial_state = {\n",
        "        \"task\": company_name,\n",
        "        \"research_summary\": \"\",\n",
        "        \"draft\": \"\",\n",
        "        \"next\": \"\",\n",
        "        \"messages\": [HumanMessage(content=f\"Research {company_name}\")]\n",
        "    }\n",
        "    \n",
        "    print(f\"üîç Debugging: {company_name}\\n\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    step_count = 0\n",
        "    for step in app.stream(initial_state):\n",
        "        step_count += 1\n",
        "        for node, output in step.items():\n",
        "            print(f\"\\nüìç Step {step_count} - Node: {node}\")\n",
        "            print(f\"   State keys: {list(output.keys())}\")\n",
        "            \n",
        "            # Check for state mismatches\n",
        "            if \"task\" in output:\n",
        "                print(f\"   ‚úÖ task: {output['task']}\")\n",
        "            if \"research_summary\" in output:\n",
        "                summary = output[\"research_summary\"]\n",
        "                print(f\"   ‚úÖ research_summary: {'Present' if summary else 'Missing'}\")\n",
        "            if \"draft\" in output:\n",
        "                draft = output[\"draft\"]\n",
        "                print(f\"   ‚úÖ draft: {'Present' if draft else 'Missing'}\")\n",
        "            if \"next\" in output:\n",
        "                print(f\"   ‚úÖ next: {output['next']}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"‚úÖ Completed in {step_count} steps\")\n",
        "\n",
        "print(\"‚úÖ Debug helper defined\")\n",
        "print(\"üí° Use debug_stream('CompanyName') to see detailed state flow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üìö Homework\n",
        "\n",
        "## Extend the Company Research Assistant with a Third Agent\n",
        "\n",
        "Choose one of the following options:\n",
        "\n",
        "### Option A ‚Äî Critic Agent\n",
        "\n",
        "Reviews the draft, scores it 1-10. If below 7, routes back to writer for revision.\n",
        "\n",
        "**Implementation hints:**\n",
        "- Add `score: int` to `SupervisorState`\n",
        "- Create `critic_node` that scores the draft\n",
        "- Update routing logic: `supervisor -> critic -> [writer (if score < 7) | FINISH]`\n",
        "\n",
        "### Option B ‚Äî Outreach Agent\n",
        "\n",
        "Takes the completed brief, drafts a personalized cold email using research signals.\n",
        "\n",
        "**Implementation hints:**\n",
        "- Add `outreach_email: str` to `SupervisorState`\n",
        "- Create `outreach_node` that generates email\n",
        "- Update routing: `writer -> outreach -> FINISH`\n",
        "\n",
        "### Option C ‚Äî Comparison Agent\n",
        "\n",
        "Accept two company names. Run two research subgraphs in parallel. Compare side-by-side.\n",
        "\n",
        "**Implementation hints:**\n",
        "- Modify `SupervisorState` to accept `task2: str`\n",
        "- Create two research subgraphs: `research_agent_1` and `research_agent_2`\n",
        "- Use parallel execution or sequential with comparison node\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "1. ‚úÖ Working code on GitHub\n",
        "2. ‚úÖ Screenshot of output\n",
        "3. ‚úÖ Brief explanation of your implementation\n",
        "\n",
        "---\n",
        "\n",
        "## üéÅ Bonus: Post on LinkedIn\n",
        "\n",
        "```\n",
        "Just built a multi-agent AI system in LangGraph.\n",
        "\n",
        "A supervisor that coordinates specialist agents to \n",
        "research companies and write briefs ‚Äî automatically.\n",
        "\n",
        "Week 3 of [course name]. We went from a single ReAct \n",
        "agent to a full orchestrated team.\n",
        "\n",
        "Graph üëá [screenshot]\n",
        "\n",
        "The thing that clicked for me: [your insight]\n",
        "\n",
        "#LangGraph #MultiAgent #AIEngineering #BuildInPublic\n",
        "```\n",
        "\n",
        "Tag the cohort. Best post gets featured in Week 4 recap.\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Resources\n",
        "\n",
        "- [LangGraph Official Documentation](https://docs.langchain.com/oss/python/langgraph/overview)\n",
        "- [LangGraph Subgraphs](https://langchain-ai.github.io/langgraph/how-tos/subgraphs/)\n",
        "- [LangGraph State Management](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)\n",
        "- [LangSmith](https://smith.langchain.com) ‚Äî Debug & trace your graphs\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Building! üéâ**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
