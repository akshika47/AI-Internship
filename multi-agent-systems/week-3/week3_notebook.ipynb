{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 3: Multi-Agent Orchestration\n",
        "\n",
        "## Supervisor Pattern, Subgraphs & Shared State\n",
        "\n",
        "Welcome to Week 3! Last week you built a single ReAct agent. Today, you'll build a **team of agents** that work together.\n",
        "\n",
        "> **Official Documentation:** This notebook follows the [LangGraph Official Documentation](https://docs.langchain.com/oss/python/langgraph/overview). All APIs and patterns used here are based on the current LangGraph specification.\n",
        "\n",
        "---\n",
        "\n",
        "## Recap & Today's Plan\n",
        "\n",
        "**Last week:** Typed State, Conditional Edges, Checkpointing, Meeting Prep Agent\n",
        "\n",
        "**Today:** Your Week 1 router + your Week 2 ReAct agent combine into a real multi-agent system.\n",
        "\n",
        "*\"Last week you built the employee. Today you build the team.\"*\n",
        "\n",
        "**Today's agenda:** \n",
        "1. Supervisor Pattern ‚Üí \n",
        "2. Shared vs Scoped State ‚Üí \n",
        "3. Subgraphs ‚Üí \n",
        "4. Live Build\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Learn Today\n",
        "\n",
        "1. **Why Multi-Agent?** ‚Äî When and why to split work across agents\n",
        "2. **Supervisor Pattern** ‚Äî The coordinator that never does the work\n",
        "3. **Shared vs Scoped State** ‚Äî What each agent sees vs what stays private\n",
        "4. **Subgraphs** ‚Äî Agents as nodes in a parent graph\n",
        "5. **Live Build** ‚Äî Company Research Assistant with 3 agents\n",
        "\n",
        "### By the End of This Notebook\n",
        "\n",
        "- Understand when to use multi-agent systems\n",
        "- Implement the Supervisor Pattern in LangGraph\n",
        "- Design shared and scoped state schemas\n",
        "- Build subgraphs and compose them into parent graphs\n",
        "- Create a working Company Research Assistant\n",
        "- Debug common multi-agent issues\n",
        "\n",
        "---\n",
        "\n",
        "### How to Use This Notebook\n",
        "\n",
        "1. **Run cells in order** - Each cell builds on the previous one\n",
        "2. **Read the markdown cells** - They contain important explanations\n",
        "3. **Experiment** - Try modifying the code to see what happens\n",
        "4. **Complete the homework** - Extend the system with a third agent\n",
        "\n",
        "**Ready? Let's start!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Installation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API Key Setup (IMPORTANT!)\n",
        "\n",
        "**To get REAL data instead of mock data, you need to set up API keys:**\n",
        "\n",
        "1. **Create a `.env` file** in the `week-3` directory\n",
        "2. **Add your API keys:**\n",
        "   ```\n",
        "   OPENAI_API_KEY=your_openai_api_key_here\n",
        "   TAVILY_API_KEY=your_tavily_api_key_here\n",
        "   ```\n",
        "\n",
        "3. **Get your API keys:**\n",
        "   - **OpenAI**: https://platform.openai.com/api-keys\n",
        "   - **Tavily**: https://tavily.com (free tier available)\n",
        "\n",
        "**Without API keys, the system will use mock data for demonstration purposes.**\n",
        "\n",
        "You can copy `.env.example` to `.env` and fill in your keys:\n",
        "```bash\n",
        "cp .env.example .env\n",
        "# Then edit .env with your actual keys\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once)\n",
        "%pip install langgraph langchain-core langchain-openai langchain ipython python-dotenv tavily-python\n",
        "\n",
        "# Verify installation\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(\"Dependencies installed successfully!\")\n",
        "print(\"Make sure you have a .env file with OPENAI_API_KEY and TAVILY_API_KEY!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import operator\n",
        "from typing import Annotated, Literal\n",
        "from typing_extensions import TypedDict\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# Load environment variables\n",
        "# Try loading from current directory first, then parent directory\n",
        "env_path = Path(\".env\")\n",
        "if not env_path.exists():\n",
        "    env_path = Path(\"../.env\")\n",
        "if not env_path.exists():\n",
        "    env_path = Path(\"../../.env\")\n",
        "\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Tavily Search import\n",
        "try:\n",
        "    from tavily import TavilyClient\n",
        "    TAVILY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TAVILY_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è  Tavily not installed. Install with: pip install tavily-python\")\n",
        "\n",
        "# Verify API keys\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üîë API Key Status:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if api_key:\n",
        "    print(\"‚úÖ OpenAI API key loaded\")\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "else:\n",
        "    print(\"‚ùå OPENAI_API_KEY not found\")\n",
        "    print(\"   üìù To fix: Create a .env file with:\")\n",
        "    print(\"      OPENAI_API_KEY=your_key_here\")\n",
        "    print(\"   üîó Get your key: https://platform.openai.com/api-keys\")\n",
        "    llm = None\n",
        "\n",
        "if tavily_key and TAVILY_AVAILABLE:\n",
        "    print(\"‚úÖ Tavily API key loaded\")\n",
        "    tavily_client = TavilyClient(api_key=tavily_key)\n",
        "else:\n",
        "    print(\"‚ùå TAVILY_API_KEY not found or Tavily not installed\")\n",
        "    if not TAVILY_AVAILABLE:\n",
        "        print(\"   üìù Install Tavily: pip install tavily-python\")\n",
        "    print(\"   üìù To fix: Add to .env file:\")\n",
        "    print(\"      TAVILY_API_KEY=your_key_here\")\n",
        "    print(\"   üîó Get your key: https://tavily.com (free tier available)\")\n",
        "    tavily_client = None\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not api_key or not tavily_key:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: Missing API keys will result in MOCK DATA\")\n",
        "    print(\"   The system will work but return placeholder responses.\")\n",
        "    print(\"   To get real data, set up your API keys in a .env file.\\n\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ All API keys configured! Ready for real data.\\n\")\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üìö Concept 1: Why Multi-Agent?\n",
        "\n",
        "## Single Agents Break When:\n",
        "\n",
        "- **Tasks have too many steps** ‚Äî context overload\n",
        "- **You need different expertise** for different parts\n",
        "- **One failure takes everything down** ‚Äî no isolation\n",
        "- **You need to run things simultaneously** ‚Äî parallel execution\n",
        "\n",
        "## Multi-Agent Systems Give You:\n",
        "\n",
        "| Benefit | Description |\n",
        "|---------|-------------|\n",
        "| **Specialization** | Each agent does one thing well |\n",
        "| **Isolation** | Failures are contained |\n",
        "| **Scalability** | Agents can run in parallel |\n",
        "| **Maintainability** | Swap one agent without breaking the rest |\n",
        "\n",
        "*\"One agent, ten tasks = one person doing every job in the company.\"*\n",
        "\n",
        "---\n",
        "\n",
        "# Concept 2: The Supervisor Pattern\n",
        "\n",
        "## The Supervisor Never Does the Work. It Only Decides Who Does.\n",
        "\n",
        "```\n",
        "User ‚Üí Supervisor ‚Üí Researcher ‚Üí Supervisor ‚Üí Writer ‚Üí Supervisor (FINISH) ‚Üí User\n",
        "```\n",
        "\n",
        "### How It Works:\n",
        "\n",
        "1. Supervisor reads the task and current state\n",
        "2. Outputs a routing decision: `researcher` / `writer` / `FINISH`\n",
        "3. Specialist agent runs and writes results to shared state\n",
        "4. Supervisor reads again and decides what's next\n",
        "5. Repeat until FINISH\n",
        "\n",
        "**The routing function** ‚Äî same conditional edges from Week 2, now routing between agents instead of tools.\n",
        "\n",
        "### Bad Supervisor Prompt:\n",
        "```\n",
        "You manage a team. Decide who goes next. Members: researcher, writer\n",
        "```\n",
        "\n",
        "### Good Supervisor Prompt:\n",
        "```\n",
        "Route to researcher if research is not done.\n",
        "Route to writer if research is done but no draft exists.\n",
        "Respond FINISH if both research and draft are complete.\n",
        "Reply with exactly one word: researcher, writer, or FINISH.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Concept 3: Shared vs Scoped State\n",
        "\n",
        "## Shared State ‚Äî Visible to Everyone\n",
        "\n",
        "The supervisor reads this to make decisions. All agents can read/write shared state.\n",
        "\n",
        "## Scoped State ‚Äî Private to a Subgraph\n",
        "\n",
        "Internal reasoning, intermediate results, tool call noise. Never reaches the supervisor.\n",
        "\n",
        "### Example:\n",
        "\n",
        "```python\n",
        "# Shared ‚Äî supervisor sees this\n",
        "class SupervisorState(TypedDict):\n",
        "    task: str\n",
        "    research_summary: str   # clean output from researcher\n",
        "    draft: str              # clean output from writer\n",
        "    next: str               # routing decision\n",
        "\n",
        "# Scoped ‚Äî researcher only\n",
        "class ResearchState(TypedDict):\n",
        "    query: str\n",
        "    raw_search_results: List[str]   # internal noise\n",
        "    research_summary: str            # only this goes back up\n",
        "```\n",
        "\n",
        "**Rule of thumb:** Shared state = what the supervisor needs + what the user sees. Everything else = scoped.\n",
        "\n",
        "**What breaks without it:** Every agent's internal tool calls, search results, and scratchpad pile into shared messages. Supervisor starts making routing decisions based on noise. Quality collapses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Concept 4: Subgraphs\n",
        "\n",
        "## A Subgraph is a Compiled LangGraph App Used as a Single Node\n",
        "\n",
        "From the parent's perspective: **black box**. Input in, output out.\n",
        "Internally: its own state, nodes, edges, loops, tools.\n",
        "\n",
        "### How It Works:\n",
        "\n",
        "```python\n",
        "# Build the subgraph\n",
        "research_graph = StateGraph(ResearchState)\n",
        "research_graph.add_node(\"search\", search_node)\n",
        "research_graph.add_node(\"summarize\", summarize_node)\n",
        "research_graph.add_edge(START, \"search\")\n",
        "research_graph.add_edge(\"search\", \"summarize\")\n",
        "research_graph.add_edge(\"summarize\", END)\n",
        "research_agent = research_graph.compile()\n",
        "\n",
        "# Drop it into the parent as a single node\n",
        "parent_graph.add_node(\"researcher\", research_agent)\n",
        "```\n",
        "\n",
        "**State handoff:** Fields that exist in both parent state and subgraph state are passed automatically. Only matching fields flow in and out.\n",
        "\n",
        "**Your Week 2 Meeting Prep Agent is already a subgraph. It just doesn't know it yet.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# What We're Building\n",
        "\n",
        "## Company Research Assistant\n",
        "\n",
        "**Three agents. One goal:** Type in a company name, get back a structured brief.\n",
        "\n",
        "| Agent | Role |\n",
        "|-------|------|\n",
        "| **Supervisor** | Reads the task, decides who acts, synthesizes the final output |\n",
        "| **Research Agent** | Runs web searches, returns a clean 3-paragraph summary |\n",
        "| **Writer Agent** | Takes the summary, writes a structured brief: Overview / Recent Developments / Outreach Signals |\n",
        "\n",
        "### Project Structure:\n",
        "\n",
        "```\n",
        "week-3/\n",
        "‚îú‚îÄ‚îÄ state.py          # SupervisorState and ResearchState\n",
        "‚îú‚îÄ‚îÄ agents/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ supervisor.py # Routing logic and FINISH condition\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ researcher.py # Research subgraph with search + summarize\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ writer.py     # Writer node that drafts the brief\n",
        "‚îú‚îÄ‚îÄ graph.py          # Wire all nodes, add conditional edges\n",
        "‚îî‚îÄ‚îÄ main.py           # Invoke and print output\n",
        "```\n",
        "\n",
        "**Let's build it step by step!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Live Build: Step 1 - Define State Schemas\n",
        "\n",
        "## Shared State (SupervisorState)\n",
        "\n",
        "This is what the supervisor sees and uses to make routing decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shared state - visible to supervisor and all agents\n",
        "class SupervisorState(TypedDict):\n",
        "    \"\"\"State shared across all agents. Supervisor reads this to make decisions.\"\"\"\n",
        "    task: str                    # Company name to research\n",
        "    research_summary: str        # Clean output from researcher (3 paragraphs)\n",
        "    draft: str                  # Clean output from writer (structured brief)\n",
        "    next: str                   # Routing decision: \"researcher\", \"writer\", or \"FINISH\"\n",
        "    messages: Annotated[list, operator.add]  # Conversation history\n",
        "\n",
        "print(\"SupervisorState defined (shared state)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scoped State (ResearchState)\n",
        "\n",
        "This is private to the research subgraph. Only `research_summary` flows back to shared state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scoped state - private to research subgraph\n",
        "class ResearchState(TypedDict):\n",
        "    \"\"\"State internal to the research subgraph. Only research_summary flows back up.\"\"\"\n",
        "    task: str                    # Matches SupervisorState.task (auto-passed)\n",
        "    raw_search_results: list      # Internal noise - never seen by supervisor\n",
        "    research_summary: str         # Clean output - flows back to SupervisorState\n",
        "    messages: Annotated[list, operator.add]  # Internal conversation\n",
        "\n",
        "print(\"ResearchState defined (scoped state)\")\n",
        "print(\"Note: 'task' and 'research_summary' match SupervisorState - they auto-flow!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Live Build: Step 2 - Research Agent (Subgraph)\n",
        "\n",
        "The research agent is a **subgraph** with two nodes:\n",
        "1. **search_node** - Runs web searches using Tavily\n",
        "2. **summarize_node** - Condenses results into 3 clean paragraphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool: Web search using Tavily\n",
        "@tool\n",
        "def tavily_search(query: str) -> str:\n",
        "    \"\"\"Search the web for information about a company.\"\"\"\n",
        "    if not tavily_client:\n",
        "        return f\"[Mock] Search results for: {query}\"\n",
        "    \n",
        "    try:\n",
        "        response = tavily_client.search(\n",
        "            query=query,\n",
        "            search_depth=\"advanced\",\n",
        "            max_results=5\n",
        "        )\n",
        "        results = []\n",
        "        for result in response.get(\"results\", []):\n",
        "            results.append(f\"Title: {result.get('title', 'N/A')}\\nContent: {result.get('content', 'N/A')}\")\n",
        "        return \"\\n\\n---\\n\\n\".join(results)\n",
        "    except Exception as e:\n",
        "        return f\"Error searching: {str(e)}\"\n",
        "\n",
        "print(\"Tavily search tool defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Node 1: Search node - runs web searches\n",
        "def search_node(state: ResearchState) -> dict:\n",
        "    \"\"\"Search the web for information about the company.\"\"\"\n",
        "    task = state.get(\"task\", \"\")\n",
        "    if not task:\n",
        "        return {\"research_summary\": \"No task provided\"}\n",
        "    \n",
        "    # Search for the company\n",
        "    search_query = f\"{task} company overview recent news\"\n",
        "    search_results = tavily_search.invoke({\"query\": search_query})\n",
        "    \n",
        "    return {\n",
        "        \"raw_search_results\": [search_results],  # Internal - stays in scoped state\n",
        "        \"messages\": [ToolMessage(content=search_results, tool_call_id=\"search_1\")]\n",
        "    }\n",
        "\n",
        "print(\"Search node defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Node 2: Summarize node - condenses search results into clean summary\n",
        "def summarize_node(state: ResearchState) -> dict:\n",
        "    \"\"\"Summarize search results into 3 clean paragraphs.\"\"\"\n",
        "    if not llm:\n",
        "        return {\"research_summary\": \"[Mock] Research summary: Company overview, recent developments, and market position.\"}\n",
        "    \n",
        "    raw_results = state.get(\"raw_search_results\", [])\n",
        "    task = state.get(\"task\", \"\")\n",
        "    \n",
        "    if not raw_results:\n",
        "        return {\"research_summary\": f\"No search results found for {task}\"}\n",
        "    \n",
        "    # Combine all search results\n",
        "    combined_results = \"\\n\\n\".join(raw_results)\n",
        "    \n",
        "    # Use LLM to create a clean 3-paragraph summary\n",
        "    prompt = f\"\"\"Based on the following search results, write a clean 3-paragraph summary about {task}.\n",
        "\n",
        "Search Results:\n",
        "{combined_results}\n",
        "\n",
        "Write exactly 3 paragraphs:\n",
        "1. Company Overview (what they do, industry, size)\n",
        "2. Recent Developments (news, product launches, partnerships)\n",
        "3. Market Position (competitors, growth, outlook)\n",
        "\n",
        "Keep it concise and factual. Only use information from the search results.\"\"\"\n",
        "\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    summary = response.content\n",
        "    \n",
        "    return {\n",
        "        \"research_summary\": summary,  # This flows back to SupervisorState!\n",
        "        \"messages\": [AIMessage(content=summary)]\n",
        "    }\n",
        "\n",
        "print(\"Summarize node defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the research subgraph\n",
        "research_graph = StateGraph(ResearchState)\n",
        "\n",
        "# Add nodes\n",
        "research_graph.add_node(\"search\", search_node)\n",
        "research_graph.add_node(\"summarize\", summarize_node)\n",
        "\n",
        "# Wire edges: START -> search -> summarize -> END\n",
        "research_graph.add_edge(START, \"search\")\n",
        "research_graph.add_edge(\"search\", \"summarize\")\n",
        "research_graph.add_edge(\"summarize\", END)\n",
        "\n",
        "# Compile the subgraph\n",
        "research_agent = research_graph.compile()\n",
        "\n",
        "print(\"Research subgraph compiled!\")\n",
        "print(\"This subgraph will be used as a single node in the parent graph\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Live Build: Step 3 - Writer Agent\n",
        "\n",
        "The writer agent takes the research summary and creates a structured brief.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Writer node - creates structured brief from research summary\n",
        "def writer_node(state: SupervisorState) -> dict:\n",
        "    \"\"\"Write a structured brief from the research summary.\"\"\"\n",
        "    if not llm:\n",
        "        return {\"draft\": \"[Mock] Structured brief:\\n\\n## Overview\\nCompany details...\\n\\n## Recent Developments\\nNews...\\n\\n## Outreach Signals\\nOpportunities...\"}\n",
        "    \n",
        "    research_summary = state.get(\"research_summary\", \"\")\n",
        "    task = state.get(\"task\", \"\")\n",
        "    \n",
        "    if not research_summary:\n",
        "        return {\"draft\": f\"No research summary available for {task}\"}\n",
        "    \n",
        "    prompt = f\"\"\"Based on the following research summary, write a structured company brief for {task}.\n",
        "\n",
        "Research Summary:\n",
        "{research_summary}\n",
        "\n",
        "Format the brief with these sections:\n",
        "1. **Overview** - Company description, industry, key facts\n",
        "2. **Recent Developments** - Latest news, product launches, partnerships\n",
        "3. **Outreach Signals** - Opportunities for engagement, pain points, growth areas\n",
        "\n",
        "Keep it professional and actionable.\"\"\"\n",
        "\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    draft = response.content\n",
        "    \n",
        "    return {\n",
        "        \"draft\": draft,\n",
        "        \"messages\": [AIMessage(content=f\"Brief written for {task}\")]\n",
        "    }\n",
        "\n",
        "print(\"Writer node defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üî® Live Build: Step 4 - Supervisor Agent\n",
        "\n",
        "The supervisor reads the state and decides who acts next. It never does the work itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Supervisor node - decides routing\n",
        "def supervisor_node(state: SupervisorState) -> dict:\n",
        "    \"\"\"Supervisor reads state and decides who acts next.\n",
        "    \n",
        "    IMPORTANT: Uses boolean state checks to prevent infinite loops.\n",
        "    Never rely solely on LLM inference for routing decisions.\n",
        "    \"\"\"\n",
        "    # Use boolean checks, not LLM inference (prevents infinite loops)\n",
        "    research_summary = state.get(\"research_summary\", \"\").strip()\n",
        "    draft = state.get(\"draft\", \"\").strip()\n",
        "    \n",
        "    # Debug: Print state to help diagnose issues\n",
        "    # print(f\"DEBUG Supervisor - research_summary: {bool(research_summary)}, draft: {bool(draft)}\")\n",
        "    \n",
        "    # Make routing decision based on state (deterministic, prevents loops)\n",
        "    # IMPORTANT: Check draft FIRST if both exist, to prevent re-running researcher\n",
        "    if draft and len(draft) > 10:  # Draft exists and is substantial\n",
        "        decision = \"FINISH\"\n",
        "    elif research_summary and len(research_summary) > 10:  # Research done, need draft\n",
        "        decision = \"writer\"\n",
        "    else:  # Need research\n",
        "        decision = \"researcher\"\n",
        "    \n",
        "    # Optional: Use LLM for logging/reasoning (but decision is already made above)\n",
        "    if llm:\n",
        "        prompt = f\"\"\"You are a supervisor managing a research team.\n",
        "\n",
        "Current state:\n",
        "- Task: {state.get('task', 'N/A')}\n",
        "- Research Summary: {'‚úÖ Complete' if research_summary else '‚ùå Missing'}\n",
        "- Draft: {'‚úÖ Complete' if draft else '‚ùå Missing'}\n",
        "\n",
        "The routing decision is: {decision}\n",
        "\n",
        "Confirm this decision is correct.\"\"\"\n",
        "\n",
        "        messages = [HumanMessage(content=prompt)]\n",
        "        try:\n",
        "            response = llm.invoke(messages)\n",
        "            reasoning = response.content\n",
        "        except:\n",
        "            reasoning = \"Decision made based on state checks\"\n",
        "    else:\n",
        "        reasoning = \"Decision made based on state checks (no LLM)\"\n",
        "    \n",
        "    # Always return lowercase decision (required by routing function)\n",
        "    decision = decision.lower() if decision != \"FINISH\" else \"FINISH\"\n",
        "    \n",
        "    return {\n",
        "        \"next\": decision,\n",
        "        \"messages\": [AIMessage(content=f\"Supervisor decision: {decision} ({reasoning[:50]}...)\")]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Supervisor node defined\")\n",
        "print(\"üí° Uses deterministic boolean checks to prevent infinite loops\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Routing function - conditional edge logic\n",
        "def route_next(state: SupervisorState) -> Literal[\"researcher\", \"writer\", \"FINISH\"]:\n",
        "    \"\"\"Route to the next agent based on supervisor's decision.\n",
        "    \n",
        "    Handles case-insensitive matching to prevent routing errors.\n",
        "    \"\"\"\n",
        "    next_agent = state.get(\"next\", \"researcher\")\n",
        "    \n",
        "    # Normalize to lowercase for comparison (handle both cases)\n",
        "    next_agent_lower = str(next_agent).lower().strip()\n",
        "    \n",
        "    if next_agent_lower == \"finish\":\n",
        "        return \"FINISH\"\n",
        "    elif next_agent_lower == \"writer\":\n",
        "        return \"writer\"\n",
        "    elif next_agent_lower == \"researcher\":\n",
        "        return \"researcher\"\n",
        "    else:\n",
        "        # Fallback: default to researcher if decision is unclear\n",
        "        print(f\"‚ö†Ô∏è  Warning: Unknown routing decision '{next_agent}', defaulting to researcher\")\n",
        "        return \"researcher\"\n",
        "\n",
        "print(\"‚úÖ Routing function defined\")\n",
        "print(\"üí° Handles case-insensitive routing decisions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üî® Live Build: Step 5 - Wire the Parent Graph\n",
        "\n",
        "Now we combine everything: supervisor, research subgraph, and writer into one graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the parent graph\n",
        "parent_graph = StateGraph(SupervisorState)\n",
        "\n",
        "# Add nodes\n",
        "parent_graph.add_node(\"supervisor\", supervisor_node)\n",
        "parent_graph.add_node(\"researcher\", research_agent)  # Subgraph as a node!\n",
        "parent_graph.add_node(\"writer\", writer_node)\n",
        "\n",
        "# Wire edges\n",
        "parent_graph.add_edge(START, \"supervisor\")\n",
        "parent_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    route_next,\n",
        "    {\n",
        "        \"researcher\": \"researcher\",\n",
        "        \"writer\": \"writer\",\n",
        "        \"FINISH\": END\n",
        "    }\n",
        ")\n",
        "parent_graph.add_edge(\"researcher\", \"supervisor\")  # Back to supervisor after research\n",
        "parent_graph.add_edge(\"writer\", \"supervisor\")      # Back to supervisor after writing\n",
        "\n",
        "# Compile the graph\n",
        "app = parent_graph.compile()\n",
        "\n",
        "print(\"‚úÖ Parent graph compiled!\")\n",
        "print(\"üí° The research subgraph is now a single node in the parent graph\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üé® Visualize the Graph\n",
        "\n",
        "Let's see the structure of our multi-agent system!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the graph structure\n",
        "try:\n",
        "    from IPython.display import Image\n",
        "    \n",
        "    # Generate graph visualization\n",
        "    graph_image = app.get_graph(xray=True).draw_mermaid_png()\n",
        "    display(Image(graph_image))\n",
        "    print(\"‚úÖ Graph visualization generated!\")\n",
        "    print(\"üí° The 'researcher' node shows as a subgraph with its internal structure\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not generate visualization: {e}\")\n",
        "    print(\"üí° Install graphviz: brew install graphviz (macOS) or apt-get install graphviz (Linux)\")\n",
        "    # Fallback: print graph structure\n",
        "    print(\"\\nGraph structure:\")\n",
        "    print(\"START -> supervisor -> [researcher | writer | FINISH]\")\n",
        "    print(\"  researcher -> supervisor (loop)\")\n",
        "    print(\"  writer -> supervisor (loop)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üöÄ Test the System\n",
        "\n",
        "Let's run the Company Research Assistant!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Streaming functions defined!\n",
            "üí° Use stream_agent_output('CompanyName') for enhanced real-time streaming\n",
            "üí° Use run_research_assistant('CompanyName') for basic streaming\n"
          ]
        }
      ],
      "source": [
        "# Enhanced streaming function with real-time output using app.stream()\n",
        "def stream_agent_output(company_name: str, max_iterations: int = 10):\n",
        "    \"\"\"Stream agent output in real-time with detailed formatting.\n",
        "    \n",
        "    This function uses app.stream() to show live updates as the agent processes.\n",
        "    \"\"\"\n",
        "    import time\n",
        "    from IPython.display import clear_output, display\n",
        "    from datetime import datetime\n",
        "    \n",
        "    initial_state = {\n",
        "        \"task\": company_name,\n",
        "        \"research_summary\": \"\",\n",
        "        \"draft\": \"\",\n",
        "        \"next\": \"\",\n",
        "        \"messages\": [HumanMessage(content=f\"Research {company_name}\")]\n",
        "    }\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "    print(f\"üöÄ STREAMING AGENT EXECUTION: {company_name}\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"‚è∞ Started at: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
        "    \n",
        "    accumulated_state = initial_state.copy()\n",
        "    iteration_count = 0\n",
        "    node_history = []\n",
        "    \n",
        "    try:\n",
        "        for step in app.stream(initial_state):\n",
        "            iteration_count += 1\n",
        "            \n",
        "            if iteration_count > max_iterations:\n",
        "                print(f\"\\n‚ö†Ô∏è  WARNING: Stopped after {max_iterations} iterations\")\n",
        "                break\n",
        "            \n",
        "            for node, output in step.items():\n",
        "                timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "                node_history.append((timestamp, node, output))\n",
        "                \n",
        "                # Format output based on node type\n",
        "                print(f\"\\n[{timestamp}] üîÑ {node.upper()}\")\n",
        "                print(\"-\" * 70)\n",
        "                \n",
        "                if node == \"supervisor\":\n",
        "                    next_decision = output.get(\"next\", \"\")\n",
        "                    print(f\"   üìç Routing Decision: {next_decision}\")\n",
        "                    \n",
        "                    # Show current state\n",
        "                    current_research = bool(accumulated_state.get(\"research_summary\", \"\").strip())\n",
        "                    current_draft = bool(accumulated_state.get(\"draft\", \"\").strip())\n",
        "                    print(f\"   üìä State Status:\")\n",
        "                    print(f\"      ‚Ä¢ Research Summary: {'‚úÖ Complete' if current_research else '‚ùå Pending'}\")\n",
        "                    print(f\"      ‚Ä¢ Draft: {'‚úÖ Complete' if current_draft else '‚ùå Pending'}\")\n",
        "                    \n",
        "                    if next_decision == \"FINISH\":\n",
        "                        print(f\"\\n   ‚úÖ Workflow Complete!\")\n",
        "                \n",
        "                elif node == \"researcher\":\n",
        "                    summary = output.get(\"research_summary\", \"\")\n",
        "                    if summary:\n",
        "                        print(f\"   üìù Research Summary Generated ({len(summary)} chars)\")\n",
        "                        print(f\"   Preview: {summary[:150]}...\")\n",
        "                    else:\n",
        "                        print(f\"   ‚ö†Ô∏è  No summary generated yet\")\n",
        "                \n",
        "                elif node == \"writer\":\n",
        "                    draft = output.get(\"draft\", \"\")\n",
        "                    if draft:\n",
        "                        print(f\"   ‚úçÔ∏è  Draft Generated ({len(draft)} chars)\")\n",
        "                        print(f\"   Preview: {draft[:150]}...\")\n",
        "                    else:\n",
        "                        print(f\"   ‚ö†Ô∏è  No draft generated yet\")\n",
        "                \n",
        "                # Accumulate state\n",
        "                for key, value in output.items():\n",
        "                    if key == \"messages\" and isinstance(value, list):\n",
        "                        if \"messages\" not in accumulated_state:\n",
        "                            accumulated_state[\"messages\"] = []\n",
        "                        accumulated_state[\"messages\"].extend(value)\n",
        "                    else:\n",
        "                        accumulated_state[key] = value\n",
        "                \n",
        "                # Check for completion\n",
        "                if output.get(\"next\") == \"FINISH\":\n",
        "                    print(f\"\\n{'=' * 70}\")\n",
        "                    print(f\"‚úÖ FINAL OUTPUT\")\n",
        "                    print(f\"{'=' * 70}\\n\")\n",
        "                    break\n",
        "        \n",
        "        # Display final results\n",
        "        final_state = accumulated_state\n",
        "        draft = final_state.get(\"draft\", \"\")\n",
        "        research_summary = final_state.get(\"research_summary\", \"\")\n",
        "        \n",
        "        if draft:\n",
        "            print(\"üìÑ COMPANY BRIEF:\")\n",
        "            print(\"-\" * 70)\n",
        "            print(draft)\n",
        "            print(\"-\" * 70)\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  No draft was generated\")\n",
        "        \n",
        "        print(f\"\\nüìä Execution Summary:\")\n",
        "        print(f\"   ‚Ä¢ Total Iterations: {iteration_count}\")\n",
        "        print(f\"   ‚Ä¢ Nodes Executed: {len(node_history)}\")\n",
        "        print(f\"   ‚Ä¢ Research Summary Length: {len(research_summary)} chars\")\n",
        "        print(f\"   ‚Ä¢ Draft Length: {len(draft)} chars\")\n",
        "        print(f\"   ‚Ä¢ Completed at: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "        \n",
        "        return final_state\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error during streaming: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return accumulated_state\n",
        "\n",
        "print(\"‚úÖ Streaming function defined!\")\n",
        "print(\"üí° Use stream_agent_output('CompanyName') to stream agent execution in real-time\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing enhanced streaming with app.stream()...\n",
            "======================================================================\n",
            "======================================================================\n",
            "üöÄ STREAMING AGENT EXECUTION: OpenAI\n",
            "======================================================================\n",
            "‚è∞ Started at: 18:47:44\n",
            "\n",
            "\n",
            "[18:47:48] üîÑ SUPERVISOR\n",
            "----------------------------------------------------------------------\n",
            "   üìç Routing Decision: researcher\n",
            "   üìä State Status:\n",
            "      ‚Ä¢ Research Summary: ‚ùå Pending\n",
            "      ‚Ä¢ Draft: ‚ùå Pending\n",
            "\n",
            "[18:48:04] üîÑ RESEARCHER\n",
            "----------------------------------------------------------------------\n",
            "   üìù Research Summary Generated (2067 chars)\n",
            "   Preview: OpenAI is an American artificial intelligence research and deployment organization founded in 2015, headquartered in San Francisco. It operates under ...\n",
            "\n",
            "[18:48:06] üîÑ SUPERVISOR\n",
            "----------------------------------------------------------------------\n",
            "   üìç Routing Decision: writer\n",
            "   üìä State Status:\n",
            "      ‚Ä¢ Research Summary: ‚úÖ Complete\n",
            "      ‚Ä¢ Draft: ‚ùå Pending\n",
            "\n",
            "[18:48:25] üîÑ WRITER\n",
            "----------------------------------------------------------------------\n",
            "   ‚úçÔ∏è  Draft Generated (3102 chars)\n",
            "   Preview: # Company Brief: OpenAI\n",
            "\n",
            "## 1. Overview\n",
            "**Company Description:**  \n",
            "OpenAI is an American artificial intelligence research and deployment organization ...\n",
            "\n",
            "[18:48:26] üîÑ SUPERVISOR\n",
            "----------------------------------------------------------------------\n",
            "   üìç Routing Decision: FINISH\n",
            "   üìä State Status:\n",
            "      ‚Ä¢ Research Summary: ‚úÖ Complete\n",
            "      ‚Ä¢ Draft: ‚úÖ Complete\n",
            "\n",
            "   ‚úÖ Workflow Complete!\n",
            "\n",
            "======================================================================\n",
            "‚úÖ FINAL OUTPUT\n",
            "======================================================================\n",
            "\n",
            "üìÑ COMPANY BRIEF:\n",
            "----------------------------------------------------------------------\n",
            "# Company Brief: OpenAI\n",
            "\n",
            "## 1. Overview\n",
            "**Company Description:**  \n",
            "OpenAI is an American artificial intelligence research and deployment organization founded in 2015 and headquartered in San Francisco, California. The organization operates under a unique corporate structure that includes a non-profit foundation and a controlled for-profit public benefit corporation (PBC). OpenAI's mission is to ensure that artificial general intelligence (AGI) benefits all of humanity, focusing on the development of highly autonomous systems capable of outperforming humans in economically valuable tasks.\n",
            "\n",
            "**Industry:**  \n",
            "Artificial Intelligence (AI) and Machine Learning\n",
            "\n",
            "**Key Facts:**\n",
            "- Founded: 2015\n",
            "- Headquarters: San Francisco, California\n",
            "- Employees: Approximately 4,000\n",
            "- Average Compensation: $1.5 million per employee (including salaries and stock-based compensation)\n",
            "- Valuation: $500 billion (as of October 2025)\n",
            "- Major Investor: Microsoft (27% stake, over $13 billion investment)\n",
            "\n",
            "## 2. Recent Developments\n",
            "**Latest News:**\n",
            "- In October 2025, OpenAI completed a significant $6.6 billion share sale, further solidifying its valuation at $500 billion.\n",
            "- The organization is preparing for a potential initial public offering (IPO), which could enhance its market position and provide substantial financial benefits to its employees.\n",
            "\n",
            "**Product Launches:**\n",
            "- OpenAI has continued to innovate with notable products, including:\n",
            "  - The GPT family of large language models\n",
            "  - The DALL-E series for text-to-image generation\n",
            "  - The Sora text-to-video models\n",
            "- The release of ChatGPT in November 2022 has generated widespread interest in generative AI technologies.\n",
            "\n",
            "**Partnerships:**\n",
            "- OpenAI has established a strong partnership with Microsoft, which has provided significant financial backing and strategic collaboration in AI development.\n",
            "\n",
            "## 3. Outreach Signals\n",
            "**Opportunities for Engagement:**\n",
            "- Collaborations with educational institutions and research organizations to further AI research and development.\n",
            "- Partnerships with businesses across various sectors to integrate OpenAI's technologies into their operations, enhancing productivity and innovation.\n",
            "\n",
            "**Pain Points:**\n",
            "- OpenAI faces criticism regarding its transition to a for-profit model, which some argue may conflict with its mission of democratizing AI. Addressing these concerns transparently could enhance public trust and stakeholder engagement.\n",
            "- Competition from other tech giants and startups in the AI landscape necessitates continuous innovation and differentiation.\n",
            "\n",
            "**Growth Areas:**\n",
            "- Expanding the application of generative AI technologies across industries such as healthcare, finance, and entertainment.\n",
            "- Enhancing user engagement and accessibility of AI tools to ensure a broader demographic can benefit from OpenAI's innovations.\n",
            "- Exploring international markets to increase global reach and impact, particularly in regions with emerging tech ecosystems.\n",
            "\n",
            "This structured brief provides a comprehensive overview of OpenAI, highlighting its mission, recent developments, and potential areas for growth and engagement.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üìä Execution Summary:\n",
            "   ‚Ä¢ Total Iterations: 5\n",
            "   ‚Ä¢ Nodes Executed: 5\n",
            "   ‚Ä¢ Research Summary Length: 2067 chars\n",
            "   ‚Ä¢ Draft Length: 3102 chars\n",
            "   ‚Ä¢ Completed at: 18:48:26\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üé¨ Test Streaming Output\n",
        "\n",
        "The `stream_agent_output()` function uses `app.stream()` to show real-time execution with:\n",
        "- Timestamps for each step\n",
        "- Detailed formatting per node type\n",
        "- State status indicators\n",
        "- Execution summary with statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test streaming with the agent\n",
        "result = stream_agent_output(\"OpenAI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üêõ What Breaks & How To Fix It\n",
        "\n",
        "## Common Issues and Solutions\n",
        "\n",
        "| Issue | Cause | Fix |\n",
        "|-------|-------|-----|\n",
        "| **Infinite loops** | Vague supervisor prompt, never reaches FINISH | Use boolean state checks, not LLM inference |\n",
        "| **State schema mismatch** | Parent calls it `task`, subgraph expects `query` | Print state keys at every node during development |\n",
        "| **Shared state noise** | All agents appending raw tool results to messages | Only write clean outputs to shared state, keep internals scoped |\n",
        "| **Subgraph output not reaching parent** | Field names don't match between schemas | Field names and types must be identical in both state schemas |\n",
        "\n",
        "**Always debug with `app.stream()` not `app.invoke()`**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Homework\n",
        "\n",
        "## Extend the Company Research Assistant with a Third Agent\n",
        "\n",
        "Choose one of the following options:\n",
        "\n",
        "### Option A ‚Äî Critic Agent\n",
        "\n",
        "Reviews the draft, scores it 1-10. If below 7, routes back to writer for revision.\n",
        "\n",
        "**Implementation hints:**\n",
        "- Add `score: int` to `SupervisorState`\n",
        "- Create `critic_node` that scores the draft\n",
        "- Update routing logic: `supervisor -> critic -> [writer (if score < 7) | FINISH]`\n",
        "\n",
        "### Option B ‚Äî Outreach Agent\n",
        "\n",
        "Takes the completed brief, drafts a personalized cold email using research signals.\n",
        "\n",
        "**Implementation hints:**\n",
        "- Add `outreach_email: str` to `SupervisorState`\n",
        "- Create `outreach_node` that generates email\n",
        "- Update routing: `writer -> outreach -> FINISH`\n",
        "\n",
        "### Option C ‚Äî Comparison Agent\n",
        "\n",
        "Accept two company names. Run two research subgraphs in parallel. Compare side-by-side.\n",
        "\n",
        "**Implementation hints:**\n",
        "- Modify `SupervisorState` to accept `task2: str`\n",
        "- Create two research subgraphs: `research_agent_1` and `research_agent_2`\n",
        "- Use parallel execution or sequential with comparison node\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "1. Working code on GitHub\n",
        "2. Screenshot of output\n",
        "3. Brief explanation of your implementation\n",
        "\n",
        "---\n",
        "\n",
        "## Bonus: Post on LinkedIn\n",
        "\n",
        "```\n",
        "Just built a multi-agent AI system in LangGraph.\n",
        "\n",
        "A supervisor that coordinates specialist agents to \n",
        "research companies and write briefs ‚Äî automatically.\n",
        "\n",
        "Week 3 of [course name]. We went from a single ReAct \n",
        "agent to a full orchestrated team.\n",
        "\n",
        "Graph [screenshot]\n",
        "\n",
        "The thing that clicked for me: [your insight]\n",
        "\n",
        "#LangGraph #MultiAgent #AIEngineering #BuildInPublic\n",
        "```\n",
        "\n",
        "Tag the cohort. Best post gets featured in Week 4 recap.\n",
        "\n",
        "---\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [LangGraph Official Documentation](https://docs.langchain.com/oss/python/langgraph/overview)\n",
        "- [LangGraph Subgraphs](https://langchain-ai.github.io/langgraph/how-tos/subgraphs/)\n",
        "- [LangGraph State Management](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)\n",
        "- [LangSmith](https://smith.langchain.com) ‚Äî Debug & trace your graphs\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Building!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
